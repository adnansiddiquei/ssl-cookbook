{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "\n",
    "dataset = MNIST('./data', train=True, download=True, transform=ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the data\n",
    "\n",
    "image, label = dataset[0]\n",
    "image.shape  # torch.Size([1, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dNet(nn.Module):\n",
    "    \"\"\"Simple 2D ConvNet that takes in 1x28x28 MNIST images and projects them with into an 8-dim\n",
    "    latent space.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "          # ConvBlock 1\n",
    "          nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, padding=3//2),\n",
    "          nn.LayerNorm((2, 28, 28)),  # normaise over each sample\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # ConvBlock 2\n",
    "          nn.Conv2d(2, 4, 7, padding=7//2),\n",
    "          nn.LayerNorm((4, 28, 28)),\n",
    "          nn.ReLU(),\n",
    "\n",
    "          # Linear Projection, output is of shape (batch_size, 8)\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(4 * 28 * 28, 8)\n",
    "        ).to(device)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"A simple contrastive loss that uses the cosine of the angle between two vectors as the\n",
    "    similarity metric.\n",
    "    \n",
    "    A larger angle means a larger loss. So this loss encourages two vectors to have a smaller \n",
    "    cosine angle between them.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y) -> torch.Tensor:\n",
    "        \"\"\"x, y should both be tensors of shape (batch_size, embedding_dim)\"\"\"\n",
    "\n",
    "        assert (\n",
    "            x.shape == y.shape\n",
    "        ), f'x (shape {x.shape}) and y (shape {y.shape}) must have the same shape'\n",
    "\n",
    "        # The cosine of the angle between two vectors is the same as the dot product between\n",
    "        # two normalised vectors\n",
    "        x = F.normalize(x, dim=-1)\n",
    "        y = F.normalize(y, dim=-1)\n",
    "\n",
    "        # This matmul will compute the dot product across every element in x, against every element\n",
    "        # in y. The leading diagonal sim[i][i] will all be 1.\n",
    "        sim = x @ y.T  # shape (batch_size, batch_size)\n",
    "\n",
    "        # we can now compute the loss as the mean of the off diagonal elemebts\n",
    "        batch_size = x.shape[0]\n",
    "        mask = torch.eye(batch_size, device=x.device).bool()\n",
    "        sim = sim.masked_fill(mask, 0)\n",
    "        loss = sim.sum() / (batch_size * (batch_size - 1))\n",
    "        \n",
    "        return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-cookbook-O0wafFVB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
